{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPG2r3uWtZbJcxZGRsplZcW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"YAhcgH1kKULE","executionInfo":{"status":"ok","timestamp":1711381436284,"user_tz":300,"elapsed":2,"user":{"displayName":"NGKD","userId":"00773922209354261622"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"V57aPhvGMbuY","executionInfo":{"status":"error","timestamp":1711381435887,"user_tz":300,"elapsed":5,"user":{"displayName":"NGKD","userId":"00773922209354261622"}},"outputId":"6fa47f69-4e58-48c8-b4b8-abe9ae67ec03"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'device' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-feac01eeb2ac>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check if the device is CUDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get the number of available CUDA devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_cuda_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"]}],"source":["# prompt:\n","\n","# Check if the device is CUDA\n","if device == \"cuda\":\n","    # Get the number of available CUDA devices\n","    num_cuda_devices = torch.cuda.device_count()\n","    # Print the number of available CUDA devices\n","    print(f\"Number of available CUDA devices: {num_cuda_devices}\")\n","    # Get the name of the current CUDA device\n","    current_cuda_device = torch.cuda.current_device()\n","    # Print the name of the current CUDA device\n","    print(f\"Current CUDA device: {torch.cuda.get_device_name(current_cuda_device)}\")\n","else:\n","    # Print a message indicating that CUDA is not available\n","    print(\"CUDA is not available.\")\n"]},{"cell_type":"code","source":["\n","def dice_score_3d(predicted, target, epsilon=1e-8):\n","    \"\"\"\n","    Compute the Dice score (F1 score) for 3D binary segmentation.\n","\n","    Args:\n","    - predicted (torch.Tensor): Predicted binary segmentation mask (0 or 1).\n","    - target (torch.Tensor): Ground truth binary segmentation mask (0 or 1).\n","    - epsilon (float, optional): Small value added to the denominator to avoid division by zero.\n","\n","    Returns:\n","    - dice_score (float): Dice score (F1 score) between predicted and target masks.\n","    \"\"\"\n","\n","    # Flatten tensors to vectors\n","    predicted_flat = predicted.view(-1)\n","    target_flat = target.view(-1)\n","\n","    # Calculate true positive (TP), false positive (FP), and false negative (FN)\n","    intersection = torch.sum(predicted_flat * target_flat)\n","    total_predicted = torch.sum(predicted_flat)\n","    total_target = torch.sum(target_flat)\n","    dice_score = (2.0 * intersection + epsilon) / (total_predicted + total_target + epsilon)\n","\n","    return dice_score.item()\n"],"metadata":{"id":"io5ZqXryQ4Do","executionInfo":{"status":"ok","timestamp":1711381435887,"user_tz":300,"elapsed":5,"user":{"displayName":"NGKD","userId":"00773922209354261622"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJ7qOf8QZFHf","executionInfo":{"status":"ok","timestamp":1711381435887,"user_tz":300,"elapsed":6,"user":{"displayName":"NGKD","userId":"00773922209354261622"}},"outputId":"09113f1c-2000-4817-9f1a-f5f4ef2cf367"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7e64bc0b70d0>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class medt_net_3d(nn.Module):\n","    def __init__(self, block, block_2, layers, num_classes=2, zero_init_residual=True,\n","                 groups=8, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None, s=0.125, img_size=256, imgchan=1):\n","        super(medt_net_3d, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm3d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = int(64 * s)\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv3d(imgchan, self.inplanes, kernel_size=7, stride=1, padding=3, bias=False)\n","        self.conv2 = nn.Conv3d(self.inplanes, 128, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.conv3 = nn.Conv3d(128, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.bn2 = norm_layer(128)\n","        self.bn3 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n","\n","\n","        self.layer1 = self._make_layer(block, int(128 * s), layers[0], kernel_size=(img_size // 2))\n","        self.layer2 = self._make_layer(block, int(256 * s), layers[1], stride=2, kernel_size=(img_size // 2),\n","                                         dilate=replace_stride_with_dilation[0])\n","\n","        self.layer3 = self._make_layer(block, int(512 * s), layers[2], stride=2, kernel_size=(img_size//4),\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, int(1024 * s), layers[3], stride=2, kernel_size=(img_size//8),\n","                                       dilate=replace_stride_with_dilation[2])\n","\n","        # Decoder\n","        self.decoder1 = nn.Conv3d(int(1024 *2*s)      ,        int(1024*2*s), kernel_size=3, stride=2, padding=1)\n","        self.decoder2 = nn.Conv3d(int(1024  *2*s)     , int(1024*s), kernel_size=3, stride=1, padding=1)\n","        self.decoder3 = nn.Conv3d(int(1024*s),  int(512*s), kernel_size=3, stride=1, padding=1)\n","        self.decoder4 = nn.Conv3d(int(512*s) ,  int(256*s), kernel_size=3, stride=1, padding=1)\n","        self.decoder5 = nn.Conv3d(int(256*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n","        self.adjust   = nn.Conv3d(int(128*s) , num_classes, kernel_size=1, stride=1, padding=0)\n","        self.soft     = nn.Softmax(dim=1)\n","\n","\n","        self.conv1_p = nn.Conv3d(imgchan, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.conv2_p = nn.Conv3d(self.inplanes,128, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.conv3_p = nn.Conv3d(128, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n","        # self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1_p = norm_layer(self.inplanes)\n","        self.bn2_p = norm_layer(128)\n","        self.bn3_p = norm_layer(self.inplanes)\n","\n","        self.relu_p = nn.ReLU(inplace=True)\n","\n","        img_size_p = img_size // 2\n","\n","        self.layer1_p = self._make_layer(block_2, int(128 * s), layers[0], kernel_size= (img_size_p//2))\n","        self.layer2_p = self._make_layer(block_2, int(256 * s), layers[1], stride=2, kernel_size=(img_size_p//2),\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3_p = self._make_layer(block_2, int(512 * s), layers[2], stride=2, kernel_size=(img_size_p//4),\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4_p = self._make_layer(block_2, int(1024 * s), layers[3], stride=2, kernel_size=(img_size_p//8),\n","                                       dilate=replace_stride_with_dilation[2])\n","\n","        # Decoder\n","        self.decoder1_p = nn.Conv3d(int(1024 *2*s)      ,        int(1024*2*s), kernel_size=3, stride=2, padding=1)\n","        self.decoder2_p = nn.Conv3d(int(1024  *2*s)     , int(1024*s), kernel_size=3, stride=1, padding=1)\n","        self.decoder3_p = nn.Conv3d(int(1024*s),  int(512*s), kernel_size=3, stride=1, padding=1)\n","        self.decoder4_p = nn.Conv3d(int(512*s) ,  int(256*s), kernel_size=3, stride=1, padding=1)\n","        self.decoder5_p = nn.Conv3d(int(256*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n","\n","        self.decoderf = nn.Conv3d(int(128*s) , int(128*s) , kernel_size=3, stride=1, padding=1)\n","        self.adjust_p   = nn.Conv3d(int(128*s) , num_classes, kernel_size=1, stride=1, padding=0)\n","        self.soft_p     = nn.Softmax(dim=1)\n","\n","    def _make_layer(self, block, planes, blocks, kernel_size=56, stride=1, dilate=False):\n","        norm_layer = nn.BatchNorm3d\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1_3d(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, groups=self.groups,\n","                            base_width=self.base_width, dilation=previous_dilation,\n","                            norm_layer=norm_layer, kernel_size=kernel_size))\n","        self.inplanes = planes * block.expansion\n","        if stride != 1:\n","            kernel_size = kernel_size // 2\n","\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer, kernel_size=kernel_size))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        xin = x.clone()\n","        print(x.shape)\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        print(x.shape)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        print(x.shape)\n","\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = F.max_pool3d(x, (2, 2, 2))\n","        x = self.relu(x)\n","        print(x.shape)\n","        # N, C, H, W, D = x.shape\n","        # x = x.view(N,C,H*W,D)\n","\n","        # x = self.maxpool(x)\n","        # pdb.set_trace()\n","        x1 = self.layer1(x)\n","        # print(x1.shape)\n","        x2 = self.layer2(x1)\n","        # print(x2.shape)\n","        x3 = self.layer3(x2)\n","        # # print(x3.shape)\n","        x4 = self.layer4(x3)\n","        # # print(x4.shape)\n","        x = F.relu(F.interpolate(self.decoder1(x4), scale_factor=(2,2,2), mode ='trilinear'))\n","        x = torch.add(x, x4)\n","        x = F.relu(F.interpolate(self.decoder2(x4) , scale_factor=(2,2,2), mode ='trilinear'))\n","        x = torch.add(x, x3)\n","        x = F.relu(F.interpolate(self.decoder3(x3) , scale_factor=(2,2,2), mode ='trilinear'))\n","        x = torch.add(x, x2)\n","        x = F.relu(F.interpolate(self.decoder4(x2) , scale_factor=(2,2,2), mode ='trilinear'))\n","        x = torch.add(x, x1)\n","        x = F.relu(F.interpolate(self.decoder5(x) , scale_factor=(2,2,2), mode ='trilinear'))\n","        print(x.shape)\n","        # N, C, _, _ = x.shape\n","        # x = x.view(N,C,256,256,256)\n","        # print(x.shape)\n","\n","        # end of full image training\n","\n","        # y_out = torch.ones((1,2,128,128))\n","        x_loc = x.clone()\n","        # x = F.relu(F.interpolate(self.decoder5(x) , scale_factor=(2,2), mode ='bilinear'))\n","        #start\n","        for i in range(0,2):\n","            for j in range(0,2):\n","              for k in range(0,2):\n","\n","                x_p = xin[:,128*i:128*(i+1),128*j:128*(j+1),128*k:128*(k+1)]\n","                # begin patch wise\n","                x_p = self.conv1_p(x_p)\n","                x_p = self.bn1_p(x_p)\n","                # x = F.max_pool2d(x,2,2)\n","                x_p = self.relu(x_p)\n","\n","                x_p = self.conv2_p(x_p)\n","                x_p = self.bn2_p(x_p)\n","                # x = F.max_pool2d(x,2,2)\n","                x_p = self.relu(x_p)\n","                x_p = self.conv3_p(x_p)\n","                x_p = self.bn3_p(x_p)\n","                # x = F.max_pool2d(x,2,2)\n","                x_p = self.relu(x_p)\n","                N, C, H, W, D = x_p.shape\n","                x_p = x_p.view(N,C,H,W*D)\n","\n","                # x = self.maxpool(x)\n","                # pdb.set_trace()\n","                x1_p = self.layer1_p(x_p)\n","                # print(x1.shape)\n","                x2_p = self.layer2_p(x1_p)\n","                # print(x2.shape)\n","                x3_p = self.layer3_p(x2_p)\n","                # # print(x3.shape)\n","                x4_p = self.layer4_p(x3_p)\n","\n","                x_p = F.relu(F.interpolate(self.decoder1_p(x4_p), scale_factor=(2,2,2), mode ='trilinear'))\n","                x_p = torch.add(x_p, x4_p)\n","                x_p = F.relu(F.interpolate(self.decoder2_p(x_p) , scale_factor=(2,2,2), mode ='trilinear'))\n","                x_p = torch.add(x_p, x3_p)\n","                x_p = F.relu(F.interpolate(self.decoder3_p(x_p) , scale_factor=(2,2,2), mode ='trilinear'))\n","                x_p = torch.add(x_p, x2_p)\n","                x_p = F.relu(F.interpolate(self.decoder4_p(x_p) , scale_factor=(2,2,2), mode ='trilinear'))\n","                x_p = torch.add(x_p, x1_p)\n","                x_p = F.relu(F.interpolate(self.decoder5_p(x_p) , scale_factor=(2,2,2), mode ='trilinear'))\n","                N, C, _, _ = x_p.shape\n","                x_p = x_p.view(N,C,128,128,128)\n","\n","                x_loc[:,128*i:128*(i+1),128*j:128*(j+1),128*k:128*(k+1)] = x_p\n","\n","        x = torch.add(x,x_loc)\n","        x = F.relu(self.decoderf(x))\n","\n","        x = self.adjust(F.relu(x))\n","\n","        # pdb.set_trace()\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n","\n","\n","\n","# Define the 3D block used in the network (replace with your specific 3D block)\n","\n","def conv1x1_3d(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv3d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class qkv_transform_3d(nn.Conv2d):\n","    \"\"\"Conv1d for qkv_transform\"\"\"\n","\n","class AxialAttention_dynamic_3d(nn.Module):\n","    def __init__(self, in_planes, out_planes, groups=8, kernel_size=56,\n","                 stride=1, bias=False, width=0):\n","        assert (in_planes % groups == 0) and (out_planes % groups == 0)\n","        super(AxialAttention_dynamic_3d, self).__init__()\n","        self.in_planes = in_planes\n","        self.out_planes = out_planes\n","        self.groups = groups\n","        self.group_planes = out_planes // groups\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.bias = bias\n","        self.width = width\n","\n","        # Multi-head self attention\n","        self.qkv_transform = qkv_transform_3d(in_planes, out_planes * 2, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.bn_qkv = nn.BatchNorm2d(out_planes * 2)\n","        self.bn_similarity = nn.BatchNorm3d(groups * 3)\n","        self.bn_output = nn.BatchNorm2d(out_planes * 2)\n","\n","        # Priority on encoding\n","\n","        ## Initial values\n","\n","        self.f_qr = nn.Parameter(torch.tensor(0.1), requires_grad=False)\n","        self.f_kr = nn.Parameter(torch.tensor(0.1), requires_grad=False)\n","        self.f_sve = nn.Parameter(torch.tensor(0.1), requires_grad=False)\n","        self.f_sv = nn.Parameter(torch.tensor(1.0), requires_grad=False)\n","\n","        # Position embedding\n","        self.relative = nn.Parameter(torch.randn(self.group_planes * 2, kernel_size * 2 - 1, kernel_size * 2 - 1), requires_grad=True)\n","        query_index = torch.arange(kernel_size).unsqueeze(0)\n","        key_index = torch.arange(kernel_size).unsqueeze(1)\n","        relative_index = key_index - query_index + kernel_size - 1\n","        self.register_buffer('flatten_index', relative_index.view(-1))\n","        if stride > 1:\n","            self.pooling = nn.AvgPool3d(stride, stride=stride)\n","\n","        self.reset_parameters()\n","        # self.print_para()\n","\n","    def forward(self, x):\n","        if self.width == 0:\n","            x = x.permute(0, 2, 1, 3, 4)\n","        elif self.width == 1:\n","            x = x.permute(0, 3, 1, 2, 4)  # N, D, C, H, W\n","        else:\n","            x = x.permute(0, 4, 1, 2, 3)\n","        N, D, C, H, W = x.shape\n","        print(\"The shape of x before the layer\", x.shape)\n","        x = x.contiguous().view(N * D, C, H, W)\n","\n","        # Transformations\n","        qkv = self.bn_qkv(self.qkv_transform(x))\n","        q, k, v = torch.split(qkv.reshape(N * D, self.groups, self.group_planes * 2, H, W),\n","                              [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=2)\n","\n","        # Calculate position embedding\n","        all_embeddings = torch.index_select(self.relative, 1, self.flatten_index).view(self.group_planes * 2, self.kernel_size, self.kernel_size, self.kernel_size)\n","        q_embedding, k_embedding, v_embedding = torch.split(all_embeddings, [self.group_planes // 2, self.group_planes // 2, self.group_planes], dim=0)\n","        qr = torch.einsum('bgcik,cijk->bgijk', q, q_embedding)\n","        kr = torch.einsum('bgcik,cijk->bgijk', k, k_embedding).transpose(2, 3)\n","        qk = torch.einsum('bgcik, bgcjk->bgijk', q, k)\n","\n","        # multiply by factors\n","        qr = torch.mul(qr, self.f_qr)\n","        kr = torch.mul(kr, self.f_kr)\n","\n","        stacked_similarity = torch.cat([qk, qr, kr], dim=1)\n","        stacked_similarity = self.bn_similarity(stacked_similarity).view(N * D, 3, self.groups, H, W, H).sum(dim=1)\n","        # stacked_similarity = self.bn_qr(qr) + self.bn_kr(kr) + self.bn_qk(qk)\n","        # (N, groups, H, W, D)\n","        similarity = F.softmax(stacked_similarity, dim=4)\n","        sv = torch.einsum('bgijk,bgcijk->bgcijk', similarity, v)\n","        sve = torch.einsum('bgijk,cijk->bgcik', similarity, v_embedding)\n","\n","        # multiply by factors\n","        sv = torch.mul(sv, self.f_sv)\n","        sve = torch.mul(sve, self.f_sve)\n","\n","        stacked_output = torch.cat([sv, sve], dim=-1).view(N * D, self.out_planes * 2, H, W)\n","        output = self.bn_output(stacked_output).view(N, D, self.out_planes, 2, H, W).sum(dim=-3)\n","\n","        if self.width == 0:\n","            output = output.permute(0, 2, 1, 3, 4)\n","        elif  self.width ==1:\n","            output = output.permute(0, 2, 3, 1, 4)\n","        else:\n","            output = output.permute(0, 2, 3, 4, 1)\n","\n","        if self.stride > 1:\n","            output = self.pooling(output)\n","\n","        return output\n","\n","    def reset_parameters(self):\n","        self.qkv_transform.weight.data.normal_(0, math.sqrt(1. / self.in_planes))\n","        # nn.init.uniform_(self.relative, -0.1, 0.1)\n","        nn.init.normal_(self.relative, 0., math.sqrt(1. / self.group_planes))\n","\n","\n","\n","class AxialBlock_dynamic_3d(nn.Module):\n","    expansion = 2\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None, kernel_size=56):\n","        super(AxialBlock_dynamic_3d, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm3d\n","        width = int(planes * (base_width / 64.))\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv_down = conv1x1_3d(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.hight_block = AxialAttention_dynamic_3d(width, width, groups=groups, kernel_size=kernel_size)\n","        self.width_block = AxialAttention_dynamic_3d(width, width, groups=groups, kernel_size=kernel_size, stride=stride, width=1)\n","        self.depth_block = AxialAttention_dynamic_3d(width, width, groups=groups, kernel_size=kernel_size, stride=stride, width=2)\n","        self.conv_up = conv1x1_3d(width, planes * self.expansion)\n","        self.bn2 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        print(\"shape of x before convdown\", x.shape)\n","        out = self.conv_down(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.hight_block(out)\n","        out = self.width_block(out)\n","        out = self.depth_block(out)\n","        out = self.relu(out)\n","\n","        out = self.conv_up(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","def MedT3d(pretrained=False, **kwargs):\n","  # Instantiate the modified 3D network\n","  model_3d = medt_net_3d(AxialBlock_dynamic_3d, AxialBlock_dynamic_3d, layers=[3, 4, 6, 3], num_classes=2)\n","  return model_3d"],"metadata":{"id":"bCbgqJPKMJ3W","executionInfo":{"status":"ok","timestamp":1711381435887,"user_tz":300,"elapsed":3392,"user":{"displayName":"NGKD","userId":"00773922209354261622"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import nibabel as nib\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","\n","class NiftiDataset(Dataset):\n","    def __init__(self, data_dir, label_dir, train=True):\n","        self.data_dir = data_dir\n","        self.label_dir = label_dir\n","        self.data_files = [f for f in os.listdir(data_dir) if f.endswith('.nii.gz')]\n","        self.label_files = [f for f in os.listdir(label_dir) if f.endswith('.nii.gz')]\n","        self.train = train\n","\n","        if train:\n","            # Use 80% of the data for training\n","            self.data_files, _ = train_test_split(self.data_files, test_size=0.2, random_state=42)\n","\n","    def __len__(self):\n","        return len(self.data_files)\n","\n","    def __getitem__(self, idx):\n","        data_path = os.path.join(self.data_dir, self.data_files[idx])\n","        label_path = os.path.join(self.label_dir, self.label_files[idx])\n","\n","        nifti_data = nib.load(data_path).get_fdata()\n","        tensor_data = torch.from_numpy(nifti_data).float()\n","\n","        nifti_label = nib.load(label_path).get_fdata()\n","        tensor_label = torch.from_numpy(nifti_label).float()\n","\n","        return tensor_data, tensor_label\n","\n","# Read the file paths and return a dataset class.\n","def readData(data_path='/content/data/Datapoint',\n","             label_path='/content/data/Annotation'):\n","    # Use 80% of the data for training, 20% for testing\n","    train_dataset = NiftiDataset(data_path, label_path, train=True)\n","    test_dataset = NiftiDataset(data_path, label_path, train=False)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    return train_loader, test_loader\n"],"metadata":{"id":"eCcf6lRbycJq","executionInfo":{"status":"ok","timestamp":1711381442849,"user_tz":300,"elapsed":780,"user":{"displayName":"NGKD","userId":"00773922209354261622"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","import torch\n","import argparse\n","\n","\n","train_data, test_data = readData()\n","\n","\n","model = MedT3d(img_size = 256, imgchan = 1)\n","\n","criterion = dice_score_3d\n","optimizer = torch.optim.Adam(list(model.parameters()), lr=0.001,\n","                             weight_decay=1e-5)\n","padding_size = (0, 0, 64, 64)\n","for batch_idx, (X_batch, y_batch, *rest) in enumerate(train_data):\n","\n","  print(X_batch.shape)\n","  print(y_batch.shape)\n","\n","\n","\n","save_dir = \"/content/data/output\"\n","\n","for epoch in range(40):\n","\n","    epoch_running_loss = 0\n","\n","    for batch_idx, (X_batch, y_batch, *rest) in enumerate(train_data):\n","        padded_X_batch = F.pad(X_batch, padding_size, value=-1)\n","        padded_y_batch = F.pad(y_batch, padding_size, value=0)\n","\n","        X_batch = padded_X_batch.to(device = 'cpu').permute(0, 4, 1, 2, 3)\n","        y_batch = padded_y_batch.to(device = 'cpu').permute(0, 4, 1, 2, 3)\n","\n","        print(padded_X_batch.shape)\n","        print(padded_y_batch.shape)\n","\n","        # ===================forward=====================\n","\n","\n","        output = model(X_batch)\n","\n","        tmp2 = y_batch[0].detach().cpu().numpy()\n","        tmp = output.detach().cpu().numpy()\n","        tmp[tmp>=0.5] = 1\n","        tmp[tmp<0.5] = 0\n","        tmp2[tmp2>0] = 1\n","        tmp2[tmp2<=0] = 0\n","        tmp2 = tmp2.astype(int)\n","        tmp = tmp.astype(int)\n","\n","        yHaT = tmp\n","        yval = tmp2\n","\n","\n","\n","        loss = criterion(output, y_batch[0])\n","\n","        # ===================backward====================\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        epoch_running_loss += loss.item()\n","\n","    # ===================log========================\n","    print('epoch [{}/{}], loss:{:.4f}'\n","          .format(epoch, 40, epoch_running_loss/(batch_idx+1)))\n","\n","\n","    if epoch == 10:\n","        for param in model.parameters():\n","            param.requires_grad =True\n","    if (epoch % 4) ==0:\n","\n","        # for batch_idx, (X_batch, y_batch, *rest) in enumerate(valloader):\n","        #     # print(batch_idx)\n","        #     if isinstance(rest[0][0], str):\n","        #                 image_filename = rest[0][0]\n","        #     else:\n","        #                 image_filename = '%s.png' % str(batch_idx + 1).zfill(3)\n","\n","        #     X_batch = Variable(X_batch.to(device='cpu'))\n","        #     y_batch = Variable(y_batch.to(device='cpu'))\n","        #     # start = timeit.default_timer()\n","        #     y_out = model(X_batch)\n","        #     # stop = timeit.default_timer()\n","        #     # print('Time: ', stop - start)\n","        #     tmp2 = y_batch.detach().cpu().numpy()\n","        #     tmp = y_out.detach().cpu().numpy()\n","        #     tmp[tmp>=0.5] = 1\n","        #     tmp[tmp<0.5] = 0\n","        #     tmp2[tmp2>0] = 1\n","        #     tmp2[tmp2<=0] = 0\n","        #     tmp2 = tmp2.astype(int)\n","        #     tmp = tmp.astype(int)\n","\n","        #     # print(np.unique(tmp2))\n","        #     yHaT = tmp\n","        #     yval = tmp2\n","\n","        #     epsilon = 1e-20\n","\n","        #     del X_batch, y_batch,tmp,tmp2, y_out\n","\n","\n","        #     yHaT[yHaT==1] =255\n","        #     yval[yval==1] =255\n","        #     fulldir = direc+\"/{}/\".format(epoch)\n","        #     # print(fulldir+image_filename)\n","        #     if not os.path.isdir(fulldir):\n","\n","        #         os.makedirs(fulldir)\n","\n","        #     cv2.imwrite(fulldir+image_filename, yHaT[0,1,:,:])\n","        #     # cv2.imwrite(fulldir+'/gt_{}.png'.format(count), yval[0,:,:])\n","        # fulldir = direc+\"/{}/\".format(epoch)\n","        # torch.save(model.state_dict(), fulldir+args.modelname+\".pth\")\n","        # torch.save(model.state_dict(), direc+\"final_model.pth\")\n","\n","        # Save model checkpoint\n","        fulldir = save_dir + \"/{}/\".format(epoch)\n","        if not os.path.isdir(fulldir):\n","            os.makedirs(fulldir)\n","\n","        torch.save(model.state_dict(), fulldir + \"MedT3d\" + \".pth\")\n","\n","torch.save(model.state_dict(), save_dir + \"final_model.pth\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":703},"id":"fDfsOpqVH4x3","executionInfo":{"status":"error","timestamp":1711381461144,"user_tz":300,"elapsed":17044,"user":{"displayName":"NGKD","userId":"00773922209354261622"}},"outputId":"68c3831f-ac0f-402f-9a66-7b55477dbb9b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 128, 1])\n","torch.Size([1, 256, 256, 256, 1])\n","torch.Size([1, 256, 256, 256, 1])\n","torch.Size([1, 1, 256, 256, 256])\n","torch.Size([1, 8, 256, 256, 256])\n","torch.Size([1, 128, 256, 256, 256])\n","torch.Size([1, 8, 128, 128, 128])\n","shape of x before convdown torch.Size([1, 8, 128, 128, 128])\n","The shape of x before the layer torch.Size([1, 128, 16, 128, 128])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"shape '[4, 128, 128, 128]' is invalid for input of size 16711680","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6b95763afa11>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4e7a529826a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4e7a529826a9>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# x = self.maxpool(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;31m# print(x1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4e7a529826a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhight_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4e7a529826a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m# Calculate position embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_planes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mq_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_planes\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_planes\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_planes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bgcik,cijk->bgijk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 128, 128, 128]' is invalid for input of size 16711680"]}]}]}